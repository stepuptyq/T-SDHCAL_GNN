# T-SDHCAL_GNN

## Models
The following 5 models are implemented in `my_model.py`:

1. **Transformer**  
   The Transformer model has potential but is currently facing issues with gradient explosion and requires further debugging.

2. **Fully Connected Neural Network (FCNN) without Time**  
   A simple fully connected network that does not utilize time information.

3. **Fully Connected Neural Network (FCNN) with Time**  
   Similar to the above but incorporates time as an additional feature. However, the error (~0.1) does not improve with the inclusion of time information.

4. **Graph Neural Network (GNN) with Time**  
   A graph-based model that uses time information to build connections between nodes.

5. **Dynamic Graph Convolutional Neural Network (DGCNN)**  
   A dynamic graph-based model designed to adaptively learn node connections.

Currently, only the FCNN models are functional, achieving an error of approximately 0.1. The GNN and DGCNN models are still under development. While their input and output dimensions have been debugged, the network architectures need to be fine-tuned based on the underlying physical information and its influence on the results.

---

## Using the GNN Model

### 1. Prepare the Data

#### Step 1: Convert ROOT Files to NPZ Files
The original data is stored in files named `PionxxGeV.root`, where `xx` represents energy levels (e.g., 10, 20, 30, 40, 50). Use the following Python script to convert these ROOT files into NPZ format:

```python
import numpy as np
import uproot

batch_size = 1000  # Number of samples to process in each batch (not used here)
index_energy = ['10', '20', '30', '40', '50']  # Energy levels

# Loop through each energy level
for ind in index_energy:
    # Define the file path for the ROOT file
    org_file_route = 'Your/Path/Pion' + ind + 'GeV.root'

    # Open the ROOT file
    file = uproot.open(org_file_route)
    
    # Extract the data object named 'tree;1'
    data_array = file['tree;1']
    
    # Convert keys and values to NumPy arrays
    keys = np.array(list(data_array.keys()))
    values = np.array(list(data_array.values()))

    # Save the extracted data as an NPZ file
    np.savez('pion' + ind + 'Gev', keys=keys, values=values)
```

#### Step 2: Split Data into Train and Test Sets
Run the script `data_processing_GNN.py`. This script combines data from all energy levels, shuffles it, and splits it into training and testing datasets. After execution, the following files will be generated:

- `data/train_indices_GNN.csv`
- `data/test_indices_GNN.csv`
- `data/train_data_GNN.npz`
- `data/test_data_GNN.npz`

#### Step 3: Generate Edge Index (Computationally Intensive)
The GNN model requires an edge index, which is generated by the script `dataset_preparation_GNN.py`. The edge index is built based on both **Euclidean distance** and **time distance**, connecting only hits that are spatially and temporally close.

> **Note:**  
> This step is very computationally intensive but only needs to be performed once. If needed, I can upload the resulting files to a cloud server for download.  
> After this step, the following files will be ready for use:
> - `dataset_train_directed.pt`
> - `dataset_test_directed.pt`

At this point, the dataset is fully prepared for training and testing.

---

### 2. Train and Test the Model

#### Environment Requirements:
- **CUDA Version:** 12.7  
- **Torch Version:** 2.4.0  

To train and test the GNN model, simply run the script `train_GNN.py`.

```bash
python train_GNN.py
```
---

This concludes the steps for preparing, training, and testing the GNN model.
